{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA Multilayer Perceptron implementation example using TensorFlow library.\\nThis example is using the MNIST database of handwritten digits\\n(http://yann.lecun.com/exdb/mnist/)\\n\\nAuthor: Aymeric Damien\\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "A Multilayer Perceptron implementation example using TensorFlow library.\n",
    "This example is using the MNIST database of handwritten digits\n",
    "(http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import input_data\n",
    "import os\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import util\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# True if you don't want to use the test data and you just want to evaluate the model\n",
    "# on the training data\n",
    "testing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('X_train.pkl') as f:\n",
    "    X_train = pickle.load(f).todense()\n",
    "with open('t_train.pkl') as f:\n",
    "    Y_train = pickle.load(f)\n",
    "with open('X_test.pkl') as f:\n",
    "    X_test = pickle.load(f).todense()\n",
    "with open('test_ids.pkl') as f:\n",
    "    test_ids = pickle.load(f)\n",
    "    \n",
    "nclass = 1 + Y_train.max()\n",
    "Y_one_hot_train = np.eye(nclass)[Y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if testing:\n",
    "    train_data, test_data, train_label, test_label = train_test_split(X_train, Y_one_hot_train, test_size=0.20, random_state=42)  \n",
    "else:\n",
    "    train_data = X_train\n",
    "    test_data = X_test\n",
    "    train_label=Y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ntrain = train_data.shape[0]\n",
    "dim = train_data.shape[1]\n",
    "ntest = test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2468 train images loaded\n",
      "618 test images loaded\n",
      "31 dimensional input\n",
      "15 classes\n"
     ]
    }
   ],
   "source": [
    "print (\"%d train images loaded\" % (ntrain))\n",
    "print (\"%d test images loaded\" % (ntest))\n",
    "print (\"%d dimensional input\" % (dim))\n",
    "print (\"%d classes\" % (nclass))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Ready to Go!\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(0)\n",
    "# Parameters\n",
    "learning_rate   = 0.001\n",
    "training_epochs = 4000\n",
    "batch_size      = ntrain\n",
    "display_step    = 1000\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 50 # 1st layer num features\n",
    "n_input    = dim # data input \n",
    "n_classes  = nclass # total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(_X, _weights, _biases):\n",
    "    layer_1 = tf.nn.relu(tf.add(tf.matmul(_X, _weights['h1']), _biases['b1'])) \n",
    "    return tf.matmul(layer_1, _weights['out']) + _biases['out']\n",
    "    \n",
    "# Store layers weight & bias\n",
    "stddev = 0.1 # <== This greatly affects accuracy!! \n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1], stddev=stddev)),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_1, n_classes], stddev=stddev))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "print (\"Network Ready to Go!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions ready\n"
     ]
    }
   ],
   "source": [
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "final_pred = tf.argmax(pred,1)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y)) \n",
    "optm = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "corr = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))    \n",
    "accr = tf.reduce_mean(tf.cast(corr, \"float\"))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "print (\"Functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# OPTIMIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000/9000 cost: 131.004425049\n",
      " Training accuracy: 0.012\n",
      " Test accuracy: 0.006\n",
      "Epoch: 1000/9000 cost: 1.592013955\n",
      " Training accuracy: 0.525\n",
      " Test accuracy: 0.515\n",
      "Epoch: 2000/9000 cost: 1.478789091\n",
      " Training accuracy: 0.622\n",
      " Test accuracy: 0.620\n",
      "Epoch: 3000/9000 cost: 1.420223832\n",
      " Training accuracy: 0.669\n",
      " Test accuracy: 0.675\n",
      "Epoch: 4000/9000 cost: 1.366180420\n",
      " Training accuracy: 0.697\n",
      " Test accuracy: 0.672\n",
      "Epoch: 5000/9000 cost: 1.230615616\n",
      " Training accuracy: 0.689\n",
      " Test accuracy: 0.667\n",
      "Epoch: 6000/9000 cost: 1.277993321\n",
      " Training accuracy: 0.682\n",
      " Test accuracy: 0.668\n",
      "Epoch: 7000/9000 cost: 1.114051700\n",
      " Training accuracy: 0.652\n",
      " Test accuracy: 0.660\n",
      "Epoch: 8000/9000 cost: 1.083078027\n",
      " Training accuracy: 0.666\n",
      " Test accuracy: 0.672\n",
      "Optimization Finished!\n",
      "CPU times: user 15min 18s, sys: 38.5 s, total: 15min 57s\n",
      "Wall time: 5min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Launch the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    total_batch = int(ntrain/batch_size)\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        randidx = np.random.randint(ntrain, size=batch_size)\n",
    "        batch_xs = train_data[randidx, :]\n",
    "        batch_ys = train_label[randidx, :]   \n",
    "        # Fit training using batch data\n",
    "        sess.run(optm, feed_dict={x: batch_xs, y: batch_ys})\n",
    "        # Compute average loss\n",
    "        avg_cost += sess.run(cost, \n",
    "                feed_dict={x: batch_xs, y: batch_ys})/total_batch\n",
    "        # Display logs per epoch step\n",
    "    if epoch % display_step == 0:\n",
    "        print (\"Epoch: %03d/%03d cost: %.9f\" % \n",
    "               (epoch, training_epochs, avg_cost))\n",
    "        train_acc = sess.run(accr, feed_dict={x: batch_xs, y: batch_ys})\n",
    "        print (\" Training accuracy: %.3f\" % (train_acc))\n",
    "        if testing:\n",
    "            test_acc = sess.run(accr, feed_dict={x: test_data, y: test_label})\n",
    "            print (\" Test accuracy: %.3f\" % (test_acc))\n",
    "    if epoch == training_epochs - 1:       \n",
    "        y_pred = sess.run(final_pred, feed_dict={x: test_data})\n",
    "        \n",
    "print (\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not testing:\n",
    "    util.write_predictions(y_pred, test_ids, 'predictions_9k_nn_orig_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
